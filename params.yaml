profile:
    # dataset: Name of data set, which is the name of the subfolder in which the data
    # files resides: 'assets/data/raw/[dataset]/. If empty, put data files in
    # 'assets/data/raw/'.
    dataset: wesad

clean:
    # target: Name of target variable.
    target: label
    
    # classification: Indicates if we are dealing with a classification case
    # (if False, a regression model will be produced).
    classification: True

    # onehot_encode_target: Whether to one-hot encode target variable or not.
    # onehot_encode_target: False
    onehot_encode_target: True

    # combine_files: Whether to combine the data from all files into one file
    # after cleaning.
    #
    # Sometimes it is desirable to not combine the data into a single file,
    # for example when:
    # - Some specific files contain data that should be reserved for the test set.
    # - We are going to use sequences of data points as input samples, and do
    #   not want sequences to overlap across files.
    #
    combine_files: False

    # percentage_zeros_threshold: If the fraction of zeros in a column is
    # larger than this threshold, the column is removed. If this parameter is
    # set to 1.0, we will only remove the columns that solely consists of
    # zeros.
    percentage_zeros_threshold: 0.5

    # correlation_metric: Which metric to measure correlation by. Choose from:
    # - pearson
    # - spearman
    # - phi_k
    # - cramers
    correlation_metric: pearson

    # input_max_correlation_threshold: If the correlation between two variables are
    # higher than this threshold, one of them will be removed. If the threshold
    # is set to 1.0, no variables will be removed.
    input_max_correlation_threshold: 1.0

featurize:
    # features: Which features to use from the data set. If empty, all columns
    # from input files are used (except those that are removed during
    # cleaning).
    features:
        - chest_ecg
        # - wrist_acc_x
        # - wrist_acc_y
        # - wrist_acc_z
        # - wrist_temp
        # - wrist_eda
        # - wrist_bvp


    # add_rolling_features (bool): Add engineered features based on rolling
    # sequence.
    add_rolling_features: False

    # remove_features (list): Features to be removed. Only useful if some of
    # the features specified above are used to create rolling features, but the
    # raw feature itself should not be included as an input.
    remove_features:
        # - wrist_acc_x
        # - wrist_acc_y
        # - wrist_acc_z
        # - wrist_temp
        # - wrist_eda
        # - wrist_bvp

    # rolling_window_size: Window size for calculating rolling features.
    rolling_window_size: 512

    # target_min_correlation_threshold: Minimum correlation between target and
    # an input feature to include the feature in the model. If set to 0.0, no
    # features will be removed based on correlation.
    # NB: Not implemented yet.
    target_min_correlation_threshold: 0.0

split:
    # train_split: Fraction of data set to use for training.
    train_split: 0.7

    # shuffle_files: If data resides in multiple files, this parameter can be
    # set to True in order to shuffle the order of the files
    shuffle_files: True

    # calibrate_split: Fraction of data set to use for calibration. If set to
    # 0, no conformal prediction is performed.
    calibrate_split: 0.0

scale:
    # Current available scaling methods are:
    # - standard
    # - minmax
    input: standard
    
    # output: Scaling method for output variable. Not applicable for
    # classification.
    output: minmax

sequentialize:
    # History window sample size
    hist_size: 2560

    # target_size: Number of points in prediction sequence. For classification
    # cases, this number will be overridden to 1.
    # Currently, a target_size greater than 1 is not supported if calibrate_split > 0
    target_size: 1

train:
    # net: Which type of neural network to use. Choose from:
    # - dnn (dense neural network)
    # - cnn (convolutional neural network
    net: cnn

    # n_epochs: Number of epochs to perform during training. If early_stopping
    # is set to True, training may be stopped before n_epochs is reached.
    n_epochs: 100

    batch_size: 128
    
    # kernel_size: Only applicable for CNN
    kernel_size: 5

    # early_stopping: Stop training if validation loss does not improve after
    # [patience] number of epochs.
    early_stopping: True

    # patience: The number of epochs to wait for validation loss to improve,
    # before stopping training early.
    patience: 10

evaluate:
